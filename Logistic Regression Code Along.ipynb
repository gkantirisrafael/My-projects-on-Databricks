{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0bd3faa9-35f3-4ebd-a0f5-4f5e14ab78bf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#We will try to predict what passengers survived the Titanic crash based on features like: age,cabin,children,etc.\n",
    "df = spark.sql('SELECT * FROM titanic_csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "42f327ad-6efd-4887-a006-b41f6c08628e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- PassengerId: integer (nullable = true)\n |-- Survived: integer (nullable = true)\n |-- Pclass: integer (nullable = true)\n |-- Name: string (nullable = true)\n |-- Sex: string (nullable = true)\n |-- Age: integer (nullable = true)\n |-- SibSp: integer (nullable = true)\n |-- Parch: integer (nullable = true)\n |-- Ticket: string (nullable = true)\n |-- Fare: float (nullable = true)\n |-- Cabin: string (nullable = true)\n |-- Embarked: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "796610ff-106a-4acd-8a6a-4a9e380d112c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[57]: ['PassengerId',\n 'Survived',\n 'Pclass',\n 'Name',\n 'Sex',\n 'Age',\n 'SibSp',\n 'Parch',\n 'Ticket',\n 'Fare',\n 'Cabin',\n 'Embarked']"
     ]
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d767d6b4-04ca-4646-a576-c0e3f2aa3b9b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#We only select useful columns for us\n",
    "my_cols=df.select(['Survived','Pclass','Sex','Age', 'SibSp', 'Parch','Fare','Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6610e1f0-bb68-40ea-9ae3-8a4c15ccebac",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Now we want to deal with the missing data(null cells)\n",
    "#We will get rid of them (drop)\n",
    "my_final_data = my_cols.na.drop()\n",
    "from pyspark.ml.feature import (VectorAssembler,VectorIndexer,OneHotEncoder,StringIndexer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "09bbe33f-0244-4e58-bf15-6e3275b30448",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#StringIndexer allows us to convert any string to a particular number \n",
    "#We will create a gender indexer now\n",
    "gender_indexer = StringIndexer(inputCol='Sex',outputCol='SexIndex')\n",
    "gender_encoder = OneHotEncoder(inputCol='SexIndex',outputCol='SexVec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b045b7cb-d355-4be5-8191-b153d4fdf629",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#We are doing the same thing for the embark column\n",
    "embark_indexer = StringIndexer(inputCol='Embarked',outputCol='EmbarkIndex')\n",
    "embark_encoder = OneHotEncoder(inputCol='EmbarkIndex',outputCol='EmbarkVec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fe43f1fd-06cf-433c-a97b-8ffdd26cc7b4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#We now will create an assembler using VectorAssembler\n",
    "assembler = VectorAssembler(inputCols=['Pclass','SexVec','EmbarkVec','Age','SibSp','Parch','Fare'],outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce29dd23-50e2-4ec1-b080-671d6b487452",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2e1b748f-1d8f-461f-b367-8db9ef14c7a4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "log_reg_titanic = LogisticRegression(featuresCol='features',labelCol='Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "34cb2951-d4d6-4653-9f0b-1b7a8d168fcb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[gender_indexer,embark_indexer,gender_encoder,embark_encoder,assembler,log_reg_titanic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fed7ed56-94be-44c3-8992-f74c29f2bb42",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Now we do the same things as in a normal model!!\n",
    "#We will split to train and testa data\n",
    "train_data,test_data = my_final_data.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e833ec77-c8a7-4fc9-b446-eeb3de7a0b9c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fit_model = pipeline.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "88779e6e-b29e-4d45-ab0a-be6165d13217",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#We tranform our test data.    We want to test our data on a test data set\n",
    "results = fit_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cfd9ec2b-d198-4676-ab22-5eb19a419409",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Its time to create evaluate\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "my_eval = BinaryClassificationEvaluator(rawPredictionCol='prediction',labelCol='Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "149e9121-ad64-4bd0-a9da-a3a19784760e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+\n|Survived|prediction|\n+--------+----------+\n|       0|       1.0|\n|       0|       1.0|\n|       0|       1.0|\n|       0|       1.0|\n|       0|       1.0|\n|       0|       1.0|\n|       0|       1.0|\n|       0|       0.0|\n|       0|       0.0|\n|       0|       0.0|\n|       0|       0.0|\n|       0|       0.0|\n|       0|       0.0|\n|       0|       0.0|\n|       0|       0.0|\n|       0|       0.0|\n|       0|       0.0|\n|       0|       0.0|\n|       0|       0.0|\n|       0|       0.0|\n+--------+----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "results.select('Survived','prediction').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b6173a6c-872e-4873-99bf-6e4ee8eb7e6e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "AUC = my_eval.evaluate(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "335695e1-5b3c-48f7-bfd4-54e978b01e89",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[73]: 0.8000388840283852"
     ]
    }
   ],
   "source": [
    "AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b6378b8c-24ab-486b-b6c6-ef71d94aacd4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Logistic Regression Code Along",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
