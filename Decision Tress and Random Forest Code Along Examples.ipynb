{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "005358db-90fe-4431-8293-e52be543856b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('tree').getOrCreate()\n",
    "data = spark.read.csv('dbfs:/FileStore/shared_uploads/gkantirisrafael@gmail.com/College.csv',inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "88b76ae2-511e-40b7-ad83-dd638497f262",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- School: string (nullable = true)\n |-- Private: string (nullable = true)\n |-- Apps: integer (nullable = true)\n |-- Accept: integer (nullable = true)\n |-- Enroll: integer (nullable = true)\n |-- Top10perc: integer (nullable = true)\n |-- Top25perc: integer (nullable = true)\n |-- F_Undergrad: integer (nullable = true)\n |-- P_Undergrad: integer (nullable = true)\n |-- Outstate: integer (nullable = true)\n |-- Room_Board: integer (nullable = true)\n |-- Books: integer (nullable = true)\n |-- Personal: integer (nullable = true)\n |-- PhD: integer (nullable = true)\n |-- Terminal: integer (nullable = true)\n |-- S_F_Ratio: double (nullable = true)\n |-- perc_alumni: integer (nullable = true)\n |-- Expend: integer (nullable = true)\n |-- Grad_Rate: integer (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c08d641c-296b-45f5-9bdb-ac291ff29075",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+----+------+------+---------+---------+-----------+-----------+--------+----------+-----+--------+---+--------+---------+-----------+------+---------+\n|              School|Private|Apps|Accept|Enroll|Top10perc|Top25perc|F_Undergrad|P_Undergrad|Outstate|Room_Board|Books|Personal|PhD|Terminal|S_F_Ratio|perc_alumni|Expend|Grad_Rate|\n+--------------------+-------+----+------+------+---------+---------+-----------+-----------+--------+----------+-----+--------+---+--------+---------+-----------+------+---------+\n|Abilene Christian...|    Yes|1660|  1232|   721|       23|       52|       2885|        537|    7440|      3300|  450|    2200| 70|      78|     18.1|         12|  7041|       60|\n|  Adelphi University|    Yes|2186|  1924|   512|       16|       29|       2683|       1227|   12280|      6450|  750|    1500| 29|      30|     12.2|         16| 10527|       56|\n|      Adrian College|    Yes|1428|  1097|   336|       22|       50|       1036|         99|   11250|      3750|  400|    1165| 53|      66|     12.9|         30|  8735|       54|\n+--------------------+-------+----+------+------+---------+---------+-----------+-----------+--------+----------+-----+--------+---+--------+---------+-----------+------+---------+\nonly showing top 3 rows\n\n"
     ]
    }
   ],
   "source": [
    "data.show(3)\n",
    "#We will try to predict if the School is private using the other columns as features!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d2189940-8d31-485e-ac86-7e1f0825163f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[75]: ['School',\n 'Private',\n 'Apps',\n 'Accept',\n 'Enroll',\n 'Top10perc',\n 'Top25perc',\n 'F_Undergrad',\n 'P_Undergrad',\n 'Outstate',\n 'Room_Board',\n 'Books',\n 'Personal',\n 'PhD',\n 'Terminal',\n 'S_F_Ratio',\n 'perc_alumni',\n 'Expend',\n 'Grad_Rate']"
     ]
    }
   ],
   "source": [
    "# Let's start to format the data\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5de5d5ce-c00a-4b16-9288-1b2063f42ad6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Lets build our assembler with the features that we believe are immportant!\n",
    "assembler = VectorAssembler(inputCols=['Apps','Accept','Enroll','Top10perc','Top25perc','F_Undergrad','P_Undergrad','Outstate','Room_Board','Books','Personal','PhD','Terminal','S_F_Ratio',\n",
    " 'perc_alumni','Expend','Grad_Rate'],outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f80ce985-c465-4427-b823-eb80dc998683",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Let's create the output and transform the data\n",
    "output = assembler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5498e36a-e161-44d9-b112-e7543d6e0d1a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Now we wanna deal with the'Private' column wich is a string. We will index it to numbers because SPARK ML LIBRARY cannot deal with this directly\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "indexer = StringIndexer(inputCol='Private',outputCol='Private_Index')\n",
    "\n",
    "#We could use the Pipeline function here if there were a lot of columns to be indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8669f019-5a3a-4429-b739-d62fc442c276",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#We now fit the indexed 'Private' column into the output data frame\n",
    "output_fixed = indexer.fit(output).transform(output) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "929ea9cb-b138-4a75-ab41-34b8f6e391ff",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- School: string (nullable = true)\n |-- Private: string (nullable = true)\n |-- Apps: integer (nullable = true)\n |-- Accept: integer (nullable = true)\n |-- Enroll: integer (nullable = true)\n |-- Top10perc: integer (nullable = true)\n |-- Top25perc: integer (nullable = true)\n |-- F_Undergrad: integer (nullable = true)\n |-- P_Undergrad: integer (nullable = true)\n |-- Outstate: integer (nullable = true)\n |-- Room_Board: integer (nullable = true)\n |-- Books: integer (nullable = true)\n |-- Personal: integer (nullable = true)\n |-- PhD: integer (nullable = true)\n |-- Terminal: integer (nullable = true)\n |-- S_F_Ratio: double (nullable = true)\n |-- perc_alumni: integer (nullable = true)\n |-- Expend: integer (nullable = true)\n |-- Grad_Rate: integer (nullable = true)\n |-- features: vector (nullable = true)\n |-- Private_Index: double (nullable = false)\n\n"
     ]
    }
   ],
   "source": [
    "output_fixed.printSchema()\n",
    "#We only need the last 2 columns(feautes,Privare_Index) that we created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "42d1b009-3199-4a10-90bd-6e03f27201d4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#These are the only columns we actually need!\n",
    "final_data = output_fixed.select('features','Private_Index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7e45e24b-6d18-4ca6-8670-1e963794df52",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#We now will split this to train data and test data\n",
    "train_data , test_data = final_data.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c914afff-7a1a-4360-9ce7-0e919cb462bc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#We will check the different classification methods that we can use\n",
    "from pyspark.ml.classification import DecisionTreeClassifier,GBTClassifier,RandomForestClassifier\n",
    "#We will see how we can use the Pipeline more\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce30eceb-9f94-4a16-8f86-d7cf91cb0131",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#We will create 3 different models here\n",
    "dtc = DecisionTreeClassifier(labelCol='Private_Index',featuresCol='features')\n",
    "rfc = RandomForestClassifier(labelCol='Private_Index',featuresCol='features',numTrees=150)\n",
    "gbt = GBTClassifier(labelCol='Private_Index',featuresCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "571f6e1c-6ec2-4404-a456-7bba4528c1b9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#We want to train all of these models.     We fit them into our train data\n",
    "dtc_model = dtc.fit(train_data)\n",
    "rfc_model = rfc.fit(train_data)\n",
    "gbt_model = gbt.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "be593904-1b77-46ea-8fef-39b3b24fb4e2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#We will check out the model comparison \n",
    "dtc_predictions = dtc_model.transform(test_data)\n",
    "rfc_predictions = rfc_model.transform(test_data)\n",
    "gbt_predictions = gbt_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "99b110a3-ea2f-4e5f-9de2-245713de7293",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Now we will get some evaluation metrics and actually see how all of these do\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "my_binary_eval = BinaryClassificationEvaluator(labelCol='Private_Index')\n",
    "my_binary_eval_2 = BinaryClassificationEvaluator(labelCol='Private_Index',rawPredictionCol='prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8c4d84ee-4d13-4c07-8c08-6ded5760855d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTC: 0.9431221719457015\nRFC: 0.9839819004524887\nGBT: 0.9605882352941182\n"
     ]
    }
   ],
   "source": [
    "#Now it's time to evaluate each of these models\n",
    "print('DTC:',my_binary_eval.evaluate(dtc_predictions)) #This is the AUC\n",
    "print('RFC:',my_binary_eval.evaluate(rfc_predictions))\n",
    "print('GBT:',my_binary_eval.evaluate(gbt_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "10b63bb1-9a2e-4da0-aac2-264a98fefd8d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[91]: 0.9361702127659575"
     ]
    }
   ],
   "source": [
    "#We use Binary classification Evaluator right now \n",
    "#If we wanna test things like accuracy or precision\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "acc_eval = MulticlassClassificationEvaluator(labelCol='Private_Index',metricName='accuracy')\n",
    "rfc_acc = acc_eval.evaluate(rfc_predictions)\n",
    "rfc_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7cca9ccf-1f0a-486d-826f-960359da20dd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Decision Tress and Random Forest Code Along Examples",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
